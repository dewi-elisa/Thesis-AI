To make tasks more efficient, an autocomplete system can predict a full sentences from a partial sentence.
To do this, the system needs to be as accurate and efficient (as few tokens as possible) as possible. 
In order to train such an autocomplete system, an encoder decoder model is made. 
The encoder extracts keywords from a sentence, and the decoder tries to predict the full sentence from these keywords.
First, the model of \citeA{autocomplete} was replicated. 
This work was one of the first to extract keywords from across the full sentence instead of the first or the last few words. 
However, this was done in an unstructured manner. 
Since human language is structured, this calls for a structured manner of extracting keywords. 
Therefore, the second model in this paper is a structured model. 
In order to achieve this, the encoder was adjusted to extract keywords using a segmentation model. 
With the help of dynamic programming algorithms the keywords could be extracted resulting in \textcolor{orange}{\dots.}

\textcolor{red}{TODO:\begin{enumerate}
    \item add results
    \item add conclusion
    \item add discussion
\end{enumerate}}

\paragraph{Keywords:} segmentation, dynamic programming, autocompletion, autoencoder, communication, latent variables